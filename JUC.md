## 1. 如何创建线程

> Java 提供了多种方式来创建和管理线程

### 1. 继承 Thread 类 并重写其 run() 方法 来创建线程

- 在 run() 方法中定义线程需要执行的任务逻辑，然后创建该类的实例，调用 start() 方法来启动线程，start() 方法会自动调用 run() 方法中的代码逻辑。
- 这种方法简单直观，但由于 Java 不支持多重继承，因此限制了类的扩展性。

### 2. 实现 Runnable 接口并将其传递给 Thread 构造器

- Runnable 是一个函数式接口，其中的 run() 方法定义了任务逻辑。这种方法更加灵活，不占用类的继承关系，同时可以更好的支持资源共享，可以让多个线程共享同一个 Runnable 实例。
- 更适用于需要解耦任务逻辑与线程管理的场景。

### 3. 实现 Callable 接口来创建有返回值的线程

- Callable 接口类似于 Runnable，但它可以返回结果并抛出异常。Callable 的 `call() 方法`需要通过 `FutureTask` 包装后传递给 Thread 构造器。通过 Future 对象可以获取线程执行的结果或捕获异常。
- 适用于需要获取线程执行结果或处理复杂任务的场景。

### 5. 通过 Executor 框架创建线程池来管理线程

- Executor 框架提供了更高级的线程管理功能，例如：线程复用、任务调度。通过 `submit()` 或 `execute()` 方法提交任务，避免频繁创建和销毁线程的开销。
- 最被常用，广泛用于需要高效管理大量线程的场景



## 2. 线程的生命周期和状态

> 在 Java 中，线程的生命周期可以分为六个状态：新建（New）、就绪（Runnable）、运行（Running）、阻塞（Blocked）、等待（Waiting）和终止（Terminated），线程在运行的整个生命周期的任意一个时刻，只可能处于其中的一个状态。

### 1. 新建

> 当一个线程对象被创建时，它处于新建状态。

- 此时线程还没有开始执行，仅仅是一个普通的 Java 对象，尚未与系统的线程调度器关联。
- 在这个阶段，线程对象已经存在，但调用 start() 方法之前，他不会进入可运行状态。

### 2. 就绪

> 当调用线程对象的 start() 方法后，线程进入就绪状态。

- 此时，线程已经被 JVM 注册到线程调度器中，但他还没有真正开始运行。线程调度器会根据操作系统的调度策略来决定何时将 CPU 时间分配给该线程。
- 注意：就绪状态的线程可能是在等待 CPU 资源，也可能已经获得了资源但尚未执行代码。

### 3. 运行

> 当线程获得 CPU 的时间片并开始执行其 run() 方法中的代码时，它进入运行状态

- 这是线程实际执行任务的状态，也是我们编写业务逻辑的地方。
- 运行状态的线程可能会因为某些原因（如 sleep()、wait() 方法）主动放弃 CPU；或因为时间片耗尽被系统强制切换回就绪状态。

### 4. 阻塞

> 当线程视图获取一个锁（例如进入同步代码块或方法），但该所正被其他线程占用时，他会进入阻塞状态。

- 此时，线程会暂停执行，知道获取到所需要的锁为止。
- 阻塞状态通常发生在多线程竞争共享资源的场景中。

### 5. 等待

> 当线程调用某些特定的方法（如 `Object.wait()`、`Thread.join()`、 `LockSupport.park()`)，他就会进入等待状态。

- 这种状态下，线程会无限期地等待，知道其他线程显式地唤醒他（例如通过 `notify()`、 `notifyAll()` 方法）。
- 等待状态通常会基于线程间的协作。

### 6. 终止

> 当线程 run() 方法执行完毕，或者由于未捕获的异常导致线程提前退出时，他会进入终止状态。

- 此时，线程的生命周期结束，无法再被启动或复用。



## 3. 线程上下文切换

> **线程上下文切换**是指当 CPU 从一个线程切换到另一个线程时，操作系统需要保存当前线程的执行状态，并加载下一个线程的执行状态，以便它们能够正确地继续运行。执行状态主要包括：寄存器状态、程序计数器（PC）、栈信息、线程的优先级等。

### 1. 发生时机

1. 时间片耗尽：OS 为每个线程分配了一个时间片，当线程的时间片用完后，OS 会强制切换其他线程，保证多个线程能公平地共享 CPU 资源。
2. 主动让出 CPU：线程调用某些特定的方法（如 `Object.wait()`、`Thread.join()`、 `LockSupport.park()`)，他就会进入等待状态，主动让出 CPU，导致上下文切换。
3. 调用了阻塞类型的系统中断：如：线程执行 IO 操作时，由于 I/O 操作通常需要等待外部资源，线程会被挂起，出发上下文切换。
4. 被终止或运行结束。

### 2. **线程上下文切换的过程**

1. 第一步是保存当前线程的上下文，将当前线程的寄存器状态、程序计数器、栈信息等保存到内存中。
2. 第二步是根据线程调度算法，如：时间片轮转、优先级调度等，选择下一个要运行的线程。
3. 第三步是加载下一个线程的上下文，从内存中恢复所选线程的寄存器状态、程序计数器和栈信息。
4. 第四步是 CPU 开始执行被加载的线程的代码。

### 3. **线程上下文切换所带来的影响**

- 线程上下文切换虽然能够实现多任务并发执行，但它也会带来 CPU 时间消耗、缓存失效以及资源竞争等问题。
- 为了减少线程上下文切换带来的性能损失，可以采取减少线程数量、使用无锁数据结构等方式进行优化。



## 4. 并发和并行的区别

> 并发和并行时多线程中两个核心概念，描述了任务执行的不同方法。

### 1. 并发

- 并发指：多个任务在同一时间段内交替执行的能力。
- 并发不一定要求任务同时执行，而是通过快速切换任务来实现“看起来同时运行的效果”。

### 2. 并行

- 并行指：多个任务在同一时刻真正同时执行的能力。
- 并行通常需要多核 CPU 支持，每个核心独立处理一个任务，实现真正的并行计算。

### 3. 区别

1. 执行方式不同：并发是任务交替执行，强调的是任务调度的时间分片；而并行是任务同时执行，强调的是多核资源的利用。
2. 对硬件要求不同：并发可以在单核 CPU 上实现，通过时间片轮转完成任务切换；而并发需要多核 CPU 的支持，每个核心独立处理一个任务。
3. 使用场景不同：并发适合 I / O 密集型任务，因为这类任务通常需要等待啊外部资源，CPU 可以切换到其他任务；而并行适合计算密集型任务，这类任务需要大量 CPU 计算，多核并行可以显著加速处理速度。
4. 核心目标不同：并发的核心目标是提高系统响应能力和资源利用率；并行的核心目标是提高系统的吞吐量和计算效率。



## 5. 同步和异步的区别

> 同步和异步是编程中两种常见的任务执行模式

### 1. 同步

- 同步指的是任务按照顺序依次执行的方式。
- 在这个模式下，调用者会阻塞等待任务完成并返回结果后，才会继续执行后续的操作。

### 2. 异步

- 异步指的是任务无需等待立即返回，调用方可以继续执行其他操作。
- 而人物的结果会在稍后通过如回调函数、事件通知或 Future 对象等待机制传递给调用方。

### 3. 同步和异步的区别

1. 执行方式不同：同步是阻塞式的，异步是非阻塞式的。
2. 响应机制不同：痛殴公布直接返回任务的结果，异步通常通过回调函数、时间通知或 Future 对象等方式传递结果。
3. 使用场景不同：同步适合简单、短时间的任务，或需要立即获取结果的场景；异步适合需要提高系统吞吐量的场景，或用于好饰家长的任务，如：网络请求、文件读写等。

## 6. 线程池七大参数

> 线程池是 Java 并发编程中的重要工具，它通过复用线程来减少线程创建和销毁的开销，从而提高系统的性能和稳定性。在 Java 中，线程池的核心实现类是 `ThreadPoolExecutor`，它提供了七个重要的参数来配置线程池的行为。

### 1. 核心线程数（`corePoolSize`）

> 指线程池中始终保持存活的线程数量，即使这些线程处于空闲状态

- 当提交一个新任务时，如果当前线程数小于核心线程数，线程池会优先创建新线程来处理任务，而不是放入队列

### 2. 最大线程数（`maximumPoolSize`）

> 指线程池中允许的最大线程数量

- 当任务队列已满且线程数小于最大线程数时，线程池会持续创建新线程来处理任务
- 如果线程数已经达到最大值，则任务会被拒绝。例如：设置 `maximumPoolSize = 10` 表示线程池最多可以创建 10 个线程

### 3. 线程空闲时间（`keepAliveTime`）

> 指非核心线程在空闲状态下保持存活的时间

- 当线程池中的线程数超过核心线程数时，多余的空闲线程会在指定的空闲时间后被回收。
- 例如：`keepAliveTime = 60` 表示非核心线程 60 秒后被销毁。

### 4. 单位时间（`unit`）

> 用于指定线程空闲时间的计量单位

- `TimeUnit.SECONDS`（秒）
- `TimeUnit.MILLISECONDS`（毫秒）

### 5. 任务队列（`workQueue`）

> 一个阻塞队列，用于存放等待执行的任务，当线程池中的线程数达到核心线程数时，新提交的任务会被放入任务队列中等待执行。

- `ArrayBlockingQueue` 有界队列，适用于控制资源使用
- `LinkedBlockingQueue` 无界队列，适用于任务量较大的场景
- `SynchronousQueue` 不存储任务的队列，适用于直接传递任务给线程的场景

### 6. 线程工厂（`threadFactory`）

> 用于创建线程池中的线程。

- 通过自定义线程工厂，可以为线程设置名称、优先级或其他属性，以便于调试和管理。
- 使用 `Executors.defaultThreadFactory()` 创建默认线程工厂

### 7. 拒绝策略（`handler`）

> 用于处理当线程池无法接受新任务时的情况（例如线程数达到最大且任务队列已满）

- `AbsortPolicy` 抛出异常，拒绝任务
- `CallerRunsPolicy` 由调用线程执行任务
- `DiscardPolicy` 直接丢弃任务
- `DiscardOldestPolicy` 丢弃队列中最旧的任务，并尝试重新提交新任务



## 8. 线程池四大拒绝策略

> 线程池是 Java 并发编程中用于管理线程的重要工具，而拒绝策略则是线程池在资源耗尽时处理新任务的一种机制。当线程池中的线程数达到最大值且任务队列已满时，线程池会根据配置的拒绝策略来决定如何处理无法接受的新任务。

### 1. `AbortPolicy`（中止策略）

- 它线程池的默认拒绝策略。当线程池无法接受新任务时，它会直接抛出 `RejectedExecutionException` 异常，终止任务的提交。
- 这种策略适用于对任务执行有严格要求的场景，例如不允许任务丢失的情况。

### 2. `CallerRunsPolicy`（调用者运行策略）

- 它会将被拒绝的任务回退给提交任务的线程执行。也就是说，任务不会被丢弃，而是由调用线程（通常是主线程）直接运行该任务
- 这种策略可以减缓任务提交的速度，从而缓解线程池的压力，但可能会导致调用线程阻塞。在这种情况下，主线程会承担部分任务的执行工作。

### 3.` DiscardPolicy`（丢弃策略）

- 它会直接丢弃无法处理的任务，并且不会抛出任何异常。
- 这种策略适用于对任务执行要求不高的场景，例如允许部分任务丢失的情况。在这种情况下，被拒绝的任务会被静默丢弃，调用方不会收到任何通知。

### 4. `DiscardOldestPolicy`（丢弃最旧任务策略）

- 它会丢弃任务队列中最旧的任务（即等待时间最长的任务），然后尝试重新提交当前任务。
- 这种策略可以确保较新的任务有机会被执行，但可能会导致某些任务被重复提交或丢失。在这种情况下，队列中最旧的任务会被移除，为新任务腾出空间。



## 9. CurrentHashMap的原理

> ConcurrentHashMap 是 Java 中常用的并发容器，它的实现从 JDK 1.7 到 JDK 1.8 发生了较大的变化，JDK 1.7 通过分段锁提高并发性能，但锁的粒度较粗，而 JDK 1.8 通过 CAS 和红黑树优化，实现了更高的并发性和查询效率，简化了实现逻辑。

### 1. JDK 1.7 版本

1. `ConcurrentHashMap` 的**实现方式**采用了**数组 + Segment + 分段锁** 的方式。`Segment` 是一种特殊的分段锁，继承了 `ReentrantLock`，每个 `Segment` 对应一个 `HashMap` 子集。
2. 它通过对某个 `Segment` 加锁实现**线程安全**。这样多个线程可以同时访问不同的 `Segment`，提高了并发性能。
3. 它的内部结构是**数组 + Segment + 分段锁**，每个 `Segment` 里面包含一个 `Entry` 数组，`Entry`数组中的元素以链表形式存储。
4. 它的**锁颗粒度**相对较小，只对需要操作的`Segment`加锁，其他 `Segment` 不受影响，从而降低锁竞争。
5. 从**查询时间复杂度**来说，最坏的情况下要遍历链表，时间复杂度为 `O(n)`
6. 从**并发性能**来说，默认有 16 个 Segment，也就是支持 16 线程同时操作，不会发生锁冲突。

### 2. JDK 1.8 版本

1. 摒弃了分段锁的**实现方式**，改用**synchronized + CAS + 红黑树**，更加高效。
2. 采用了 `CAS` 操作（`Compare-And-Swap`）保证**并发安全**，必要时使用`Synchronized`来解决并发冲突。
3. 采用**数组 + 链表 + 红黑树**的**数据结构**。链表长度超过阈值（8），转化为红黑树，从而优化查询性能。
4. **锁的颗粒度**细化到桶（Node），并且 value 和 next 使用 `volatile` 修饰，保证并发的可见性。
5. 从**查询时间复杂度**上来说，链表为 `O(n)`，使用红黑树降为`O(logN)`
6. 从**并发性能**来讲，并发颗粒度与数组长度相关，每个桶可以独立加锁，支持更高的并发度。



## 10. 线程死锁

> 线程死锁是多线程编程中一个常见的问题，它会导致程序陷入一种无法继续执行的状态。

### 1. **什么是线程死锁**

- 它是指两个或多个线程在执行过程中，因为争夺资源而相互等待对方释放资源，从而导致所有相关线程都无法继续执行的情况。
- 例如，线程 A 持有资源 1 并等待资源 2，而线程 B 持有资源 2 并等待资源 1，这样两个线程就会陷入互相等待的状态，形成死锁。

### 2. **线程死锁的产生条件**

1. 互斥条件：资源只能被一个线程占用，其他线程必须等待资源释放后才能使用。
2. 占有且等待：线程已经占有了某些资源，并且正在等待获取其他被占用的资源。
3. 不可剥夺条件：线程持有的资源不能被强制剥夺，只有线程自己可以释放资源。
4. 循环等待条件：存在一组线程形成循环等待，每个线程都在等待下一个线程所占有的资源。

## 11. 如何预防和避免线程死锁

1. 破坏互斥条件**，**我们可以尽量减少对共享资源的独占性访问。 使用无锁数据结构来替代传统的同步机制，比如：ConcurrentHashMap、AtomicInteger 等。对于只读资源，可以通过复制或缓存的方式避免竞争。
2. 破坏占有且等待条件，我们可以要求线程在开始执行前一次性获取所有需要的资源。如果无法获取所有资源，则释放已占有的资源并稍后重试。这种方法被称为“一次性申请所有资源”，但需要注意的是，它可能会增加资源的竞争压力。
3. 破坏不可剥夺条件，我们可以允许系统强制剥夺线程占有的资源。这种方法通常用于操作系统层面，但在 Java 中并不常见，因为强制剥夺资源可能会导致数据不一致或复杂的恢复逻辑。
4. 破坏循环等待条件，我们可以为资源分配一个全局的顺序编号，并要求线程按照固定的顺序申请资源。



## 12. synchronized 底层原理

> synchronized 用于保证多线程环境下的数据一致性。

### 1. **什么是synchronized**

它是一种内置的锁机制，它可以作用于方法或代码块，用于控制多个线程对共享资源的访问。当一个线程进入 synchronized 保护的代码区域时，它会尝试获取锁；如果锁已被其他线程占用，则当前线程会被阻塞，直到锁被释放。锁的持有者在退出同步代码块或方法时会自动释放锁，从而允许其他线程继续执行。

### 2. **synchronized 的底层是如何实现**

1. 依赖于 JVM 的监视器锁（monitor）机制
2. 每个对象有一个监视器锁（monitor）
3. 当 monitor 被占用时就会处于锁定状态，线程执行 monitorenter 指令时尝试获取锁，会判断 monitor 的进入数是否为 0 
   - 如果为 0 则该线程进入monitor，然后将进入数设置为 1，该线程即为monitor的所有者；
   - 如果不为 0，说明已有线程占有该monitor，那么线程就会进入并处于阻塞状态，直到monitor的进入数为 0，才会重新尝试获取monitor的所有权。
4. 退出同步代码块时，线程会执行 monitorexit，该线程必须是 objectref 所对应的 monitor 的所有者。
5. 指令执行时，monitor 的进入数减 1，如果减 1 后进入数为 0，那线程退出 monitor，不再是这个 monitor 的所有者。其他被这个 monitor 阻塞的线程可以尝试去获取这个 monitor 的所有权。

### 3. **synchronized 的优缺点**

- 优点：简单易用，无需手动管理锁的获取和释放。底层经过多次优化，性能在大多数场景下已经足够高效。
- 缺点：在高并发场景下，重量级锁可能会导致性能瓶颈。不支持锁的中断或超时等高级功能（相比之下，ReentrantLock 提供了更灵活的锁机制）。



## 13. synchronized和ReentrantLock的区别

> synchronized 和 ReentrantLock 是 Java 中实现线程同步的两种主要方式，它们都能保证多线程环境下的数据一致性

### 1. 概念上的区别

- synchronized 是 Java 的内置关键字，它是**隐式**的，通过**JVM 提供的监视器锁机制实现同步**，使用简单，无需手动管理锁的获取和释放。
- ReentrantLock 是 `java.util.concurrent.locks`包中的一个类，它是**显式**的，提供了更加灵活的锁机制，需要开发者**手动调用 lock() 和 unlock() 方法**来控制锁的生命周期。

### 2. 功能特性上的区别

ReentrantLock 提供了比 synchronized 更丰富的功能，比如：

- ReentrantLock 支持在**等待锁的过程中响应中断**，synchronized **不支持中断**
- ReentrantLock 提供了 **tryLock() 方法**，**允许线程尝试获取锁，并在指定时间内返回结果**，而 synchronized 必须一直等待锁释放。

### 3. 性能上的区别

synchronized 和 ReentrantLock 在不同场景下各有优势

- 对于**低竞争场景**，由于 synchronized 提供了更多的灵活性（如偏向锁、轻量级锁），一般与 ReentrantLock 相当甚至更好
- 对于**高竞争场景**，ReentrantLock 提供了更多的灵活性（如公平锁、可中断锁等），更适合复杂需求

### 4. 锁的释放与异常处理上的区别

- synchronized 在推出同步代码块时会**自动释放锁**，即使发生异常也不会导致死锁
- 而 ReentrantLock 需要开发者手动调用 unlock() 方法释放锁，因此必须在 finally 块中确保锁的释放，否则可能导致死锁。



## 14. 锁的状态与升级过程

### 1. 锁的状态

> 在Java中，synchronized关键字和ReentrantLock等锁机制都涉及锁的状态管理。锁的状态通常可以分为以下几种：

- 无锁状态（Unlocked）：当一个对象或资源没有被任何线程持有锁时，它处于无锁状态。此时，多个线程可以自由访问该资源。
- 偏向锁（Biased Locking）：偏向锁是一种优化机制，用于减少无竞争情况下的同步开销。当一个线程第一次获取锁时，JVM会将锁标记为偏向该线程，并记录线程ID。如果后续该线程再次尝试获取锁，无需进行额外的同步操作，直接判断线程ID是否匹配即可。偏向锁适用于只有一个线程访问同步块的场景。
- 轻量级锁（Lightweight Locking）：当有第二个线程尝试获取已经被偏向的锁时，偏向锁会升级为轻量级锁。轻量级锁通过CAS（Compare-And-Swap）操作来尝试获取锁。如果CAS操作成功，则线程获取锁；如果失败，则进入自旋等待状态，尝试多次获取锁。
- 重量级锁（Heavyweight Locking）：当多个线程竞争锁且自旋等待无法快速获取锁时，轻量级锁会升级为重量级锁。重量级锁会将未获取锁的线程挂起（进入阻塞状态），并由操作系统调度。这种方式会带来较大的性能开销，因为线程的挂起和唤醒需要上下文切换。

### 2. 锁的升级过程

> 锁的升级过程是一个从低开销到高开销的逐步演化过程，目的是在不同竞争程度下选择最优的锁实现。以下是锁升级的具体流程：

- 初始状态：无锁，对象刚创建时，没有任何线程竞争锁，处于无锁状态。
- 偏向锁，第一个线程尝试获取锁时，JVM会将锁标记为偏向锁，并记录线程ID。后续该线程再次尝试获取锁时，只需检查线程ID是否匹配，无需额外操作。
- 轻量级锁，当第二个线程尝试获取锁时，偏向锁失效，升级为轻量级锁。轻量级锁通过CAS操作尝试获取锁。如果CAS操作失败，线程会进入自旋状态，反复尝试获取锁。
- 重量级锁，如果自旋一定次数后仍然无法获取锁，或者系统检测到锁竞争激烈，轻量级锁会升级为重量级锁。重量级锁会将未获取锁的线程挂起，避免CPU资源浪费。

### 3. 锁升级的意义

> 锁升级的核心目的是在不同的竞争场景下平衡性能和资源消耗：

- 偏向锁：适合单线程频繁访问的场景，减少同步开销。
- 轻量级锁：适合少量线程竞争的场景，利用CAS和自旋提高效率。
- 重量级锁：适合高竞争场景，避免线程长时间占用CPU资源。

### 4. 锁降级

- 需要注意的是，锁的升级是单向的，即从无锁 → 偏向锁 → 轻量级锁 → 重量级锁。一旦锁升级为重量级锁，就不会再降级为轻量级锁或偏向锁。



## 15. 乐观锁

> 乐观锁是一种并发控制机制

### 1. **什么是乐观锁**

- 它是一种基于“无锁”思想的并发控制机制。
- 它假设多线程操作之间很少发生冲突，因此在读取数据时不会加锁，而是通过某种机制（如版本号或时间戳）来检测数据是否被其他线程修改过。
- 如果检测到数据未被修改，则提交更新；如果检测到数据已被修改，则根据策略进行处理（如重试或抛出异常）。

### 2. **乐观锁的实现方式**

1. **版本号机制：**为数据添加一个版本号字段，每次更新时递增版本号，并在更新时验证版本号是否匹配。
2. **CAS 操作：**使用比较并交换（Compare-And-Swap）指令，直接在硬件层面实现无锁操作。CAS 操作包含内存位置（V）、预期值（A）和新值（B）这三个参数。只有当内存位置的值等于预期值时，才会将内存位置的值更新为新值。

### 3. **乐观锁的特点**

1. 无锁设计，乐观锁不依赖传统的锁机制，减少了线程阻塞和上下文切换的开销。
2. 性能好，在低冲突场景下，乐观锁的性能优于悲观锁，因为它避免了锁的竞争。
3. 支持冲突检测，乐观锁通过版本号或 CAS 操作检测冲突，但需要开发者显式处理冲突（如重试或回滚），这可能会增加代码的复杂性。

### 4. **乐观锁的适用场景**

1. 读多写少的场景，例如缓存系统、统计计数器等，读操作远多于写操作，冲突概率较低。
2. 在分布式环境中，乐观锁可以通过版本号或时间戳实现跨节点的数据一致性。
3. 高并发环境，在高并发场景下，乐观锁可以减少锁的竞争，从而提高系统的吞吐量。

**注意：**乐观锁并不适合写操作频繁或冲突概率较高的场景，因为频繁的冲突会导致大量的重试操作，反而降低性能。



